\input{template.tex}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\newcounter{Chapcounter}
%\newcommand\showmycounter{\addtocounter{Chapcounter}{1}\themycounter}
\newcommand{\lecture}[1] 
{ {\newpage
  \phantomsection %This is too make sure that the toc points to the correct page. Make sure the this doens't break.
  \newpage
  \addtocounter{Chapcounter}{1} \Large \underline{\textbf{ \color{Sepia} Lecture \theChapcounter:}} }   
  \addcontentsline{toc}{section}{ \color{Sepia} Lecture:~\theChapcounter~~#1}    
}
\usepackage{eso-pic}


\newlist{Properties}{enumerate}{2}
\setlist[Properties]{label=Property \arabic*.,itemindent=*}


%\pagecolor[rgb]{0.98, 0.96, 0.89}

%\usepackage[pages=some]{background}

%\backgroundsetup{
%scale=1,
%color=black,
%opacity=0.4,
%angle=0,
%contents={%
%  \includegraphics[width=\paperwidth,height=\paperheight]{scroll-background}
%  }%
%}

\pagecolor[rgb]{0.94,0.86,0.69} %Trying to get that old paper look. 
\color[rgb]{0.2,0.2,0.2} %Trying to get a more faded text look.


\author{Rindra Razafy, ``Hagamena''}
\title{Borcherd Algebraic Geometry 1}
\setcounter{section}{-1}
\begin{document}
\maketitle
%\AddToShipoutPictureBG{\includegraphics[width=\paperwidth,height=\paperheight]{scroll-background}};

%\tikz[remember picture,overlay] \node[opacity=0.3,inner sep=0pt] at (current page.center){\includegraphics[width=\paperwidth,height=\paperheight]{scroll-background}};

\tableofcontents

\newpage

\section{Prologue}
Some quick notes summarising the ``Algebraic geometry 1'' video lectures from R.E. Borcherds, found \href{https://youtube.com/playlist?list=PL8yHsr3EFj53j51FG6wCbQKjBgpjKa5PX}{here}.

\lecture{}
\section{Introduction}
\subsection{Examples}
\subsubsection{Pythagorean triangles}
\textbf{Problem:} How do we classify all Pythagorean triangles.

We will look at two ways of solving this:\begin{enumerate}
    \item \textbf{Algebraic way:} 
    We want to solve\begin{equation}
        x^2+y^2 = z^2 \text{ with }x,y,z\text{ coprime integers}
    \end{equation}
    
    If we look at the equation mod $4$ we notice that $x^2,y^2,z^2 \equiv 0,1 \mod 4$, since the squares mod $4$ all take these forms.
    
    So $z$ is odd and WLOG we assume that $x$ is even and $y$ is odd. 
    We rearange the equation:\begin{equation}
        y^2 = z^2-x^2 = (z-x)(z+x)
    \end{equation}
    Assume that $z-x = dm_1$ and $z+x = dm_2$, therefore we have that $2z = d(m_1+m_2)$ and $2x = d(m_2-m_1)$, then since $d\mid 2z$ and $d\mid 2x$, and $\gcd(x,z) = 1$ we have two cases, either $d$ divides both $x$ and $z$, which would imply that $d=1$.
    
    Or $d$ divides $2$ which means that $d = 1$, or $d=2$. But note that since $x,z$ are of opposite parity $z+x$ is odd so $d\neq 2$.
    
    So in all cases, $d = 1$. So $(z-x)$ and $(z+x)$ are coprime.
    
    But since their product is a square this implies that $z-x$ and $z+x$ are squares, so:\begin{equation}
        z-x = r^2, \text{ and }z+x = s^2, \text{ where }s,r\text{ are odd and coprime}
    \end{equation}
    
    So we conclude that $z = \frac{r^2+s^2}{2}$, $x = \frac{s^2-r^2}{2}, y=rs $ for any $r,s$ odd and coprime.
    
    \item \textbf{Geometric solution}
    Let $X = \frac{x}{z}$, $Y = \frac{y}{z}$ and we want to solve\begin{equation}
        X^2+Y^2=1, \ X,Y\text{rational}
    \end{equation}
    
    So we are looking for rational points on the unit circle.
    
    Note if we draw the line from $(-1,0)$ to $(X,Y)$ on the unit circle with $X,T\in \Q$.It will intersect the y-axis at the point $(0,t)$ where $t=\frac{Y}{X+1}\in \Q$.
    
    Conversely, if we are given $t$ we can find $(X,Y)$, since we know that\begin{equation*}
        Y=t(X+1) \text{ and }t^2{(X+1)}^2 + X^2 = 1 \Rightarrow (X+1)((t^2+1)X+t^2-1) = 0
    \end{equation*}
    And finding roots we see that $X = \frac{1-t^2}{1+t^2}$ and $Y=\frac{2t}{1+t^2}$, for $t\in \Q$.
    
    \
    
    So there is a correspondence between points on the circle except for the point at $(-1,0)$ and points on the $y-$axis. This is what is called a Birational Equivalence.
    
    \begin{definition}
        \textbf{Birational Equivalence}
        An equivalence excepts on subsets of co-dimension at least $1$.
    \end{definition}
\end{enumerate}
Treating this problem as a geometrical problem gives us additional insights. Indeed, for example the circle forms a group of rotations with operation:\begin{equation}
    (x_1,y_1)\times (x_2,y_2) = (x_1x_2-y_1y_2,x_1y_2+x_2y_1)
\end{equation}

This is the cosine and sign of the sum of two angles, indeed if $(x_1,y_1) = (\cos\theta_1,\sin\theta_1)\text{ and }(x_2,y_2) = (\cos\theta_2,\sin\theta_2)$ then:\begin{equation}
 (\cos\theta_1,\sin\theta_1)\times (\cos\theta_2,\sin\theta_2) = (\cos\theta_1\cos\theta_2-\sin\theta_1\sin\theta_2, \dots) = (\cos(\theta_1+\theta_2),\sin(\theta_1+\theta_2))
\end{equation}
This is the simplest example of what is called an Algebraic group.

\begin{definition}
    \textbf{Algebraic Groups} We can think of this as functor from (commutative) Rings to Groups.

    \begin{equation}
        G\colon R\rightarrow (\{(x,y)\in R^2\mid x^2+y^2=1\},\times)
     \end{equation}
     Where the operation is defined as above, and the identity is $(1,0)$ and ${(x,y)}^{-1} = (x,-y)$.
     
\end{definition}

\begin{example}
    $G(\C) = \{(x,y)\in\C \mid x^2+y^2 = 1\}$
\end{example} 

But note that $1 = x^2+y^2 = {\underbrace{(x+iy)}_z}{\underbrace{(x-iy)}_{\overline{z}}}$. So we see that \begin{equation}
    G(\C) = \{(x,y)\in\C \mid x^2+y^2 = 1\}\simeq \{z\in \C \mid z\text{ is invertible}\} = \C^\ast
\end{equation}

\textbf{Summary}
There are many ways to view a circle:\begin{enumerate}
    \item Subset of $\R^2$
    \item Polynomial $x^2+y^2-1 \rightarrow$   Algebraic set
    \item Ideal $(x^2+y^2-1)$ in ring $\R[x,y]$.
    \item Ring $\R[x,y]/(x^2+y^2-1) = $ coordinate ring of $S^1$. Can be seen as the set of polynomials on the circle.
    \item (Smooth) manifold
    \item Group (Algebraic Group)
    \item Functor from Rings to Groups or Sets (Grothendieck)
\end{enumerate}

\section{Two cubic curves}
In this section we will discuss some cubic cubes.\begin{enumerate}
    \item $y^2 = x^3+x^2$
    
There is almost a 1-to-1 correspondence between $(x,y)$ rational on this curve and $t\in \Q$, via $t = \frac{y}{x}$, the slope of the line through $(x,y)$ and the origin. 
Indeed since $y=tx$, if $x\neq 0$, we have:\begin{equation}
    t^2x^2 = x^3+x^2 \Rightarrow t^2 = 1+x \Rightarrow x=t^2-1 \text{ and } y=t^3-t 
\end{equation}

We don't quite get a 1--1 correspondence because $t=1$ and $t=-1$ both correspond to $(x,y) = (0,0)$. 

So we can think of this cubic curve as a copy of $\Q$, but two of these points are mapped to the same point.

\begin{definition}
    Resolution of Singluarity
    A singularity is a ``bad'' point of our curve, and a resolution is getting a ``nice'' map from a curve without singularities to our curve.    
\end{definition} 

\

The resolution in the above case is done by a process called ``blowing-up''.
\begin{remark}
    Hironaka, showed that blowing-up resolves singularites in zero characteristic. (The problem in non-zero characteristic is still unsolved).
\end{remark}
\begin{remark}
    Finding rational points on curves can be difficult. For example:\begin{equation}
        x^n + y^n = 1 \Rightarrow X^n+Y^n=Z^n \text{ where }x=X/Z \text{ and }y=Y/Z
    \end{equation}
    This is Fermat's Last Theorem, which was very hard to solve.        
\end{remark}

\item $x^3+y^3 = 9$

Note on this curve we can define an algebraic operation ``+'', if we add in a point at infinity.
In that case, the point at infinity is the identity ``0'', and $a,b,c$ on the curve lie on a line if and only if $a+b+c = 0$ in the group. To check that the group operation is associative we use the fact that: $a_1+a_2+\cdots = b_1+b_2+\dots \iff $there is a rational function with poles at $a_i$ and zeroes at the $b_i$.

\begin{definition}
    Groups of this kind are called \textbf{elliptic curves}, there are the 1-dimensional case of what is called \textbf{Abelian varieties}. 
    Abelian varieties are algebraic groups that are ``projective'', roughly they have no missing points.
\end{definition} 

\end{enumerate}

\section{Bézout, Pappus, Pascal}
\subsection{Bézout's theorem}
\begin{theorem} \textbf{Bézout}
    Informally: Two curves of degree $m,n$ in the plane have at most $mn$ intersection, if they have no components in common.    

    \textbf{Stronger version of Bézout}
    There have exactly $mn$ intersection points if:\begin{enumerate}
        \item We are working over $\C$
        \item Count points at infinity
        \item Counting multiplicities (for example a straight line tangent to a parabola, we need to count the intersection point as two points).
    \end{enumerate}
\end{theorem}
This theorem was originally stated by Newton, though he didn't really prove it.

\

It is actually quite difficult to make sense of multiplicities.

\begin{proof}
    Informal proof: Suppose the curves are $f(x,y) = 0$ of degree $m$ and $g(x,y) = 0$ of degree $n$.

    Perturb $f,g$ so that $f = p_1\dots p_m$ and $g = q_1\dots q_n$, with $p_i.q_j$ linear.

    Problem: How do we know the number of intersection points doesn't change as we perturb $f,g$
\end{proof}

This style of proof was very common in the Italian School of Algebraic Geometry, but with these informal reasonings caused them to introduce many false theorems.

Weil and Zariski put Algebraic Geometry on much firmer foundations, but the proofs became much more complicated. 

Nowadays, these informal proofs are mostly useful just to guess what the right answer is (for example understanding the reasoning for the above proof, we can understand the reasoning for 
the anologue of Bézout's theomre in higher dimensions).


\subsection{Pappus' theorem}

\begin{theorem}
    Informally: Take two straight lines in the plane and on each line choose any three points.
Number them and join them to every point of a different number on the other line, looking at the intersection point of these lines.
These three intersection points lie on a straight line.
\end{theorem}

This theorem is equivalent to commutativity in multiplication. If we look at the anologuous result in a plane over a division ring then:\begin{equation*}
    \text{Pappus' theorem is true }\iff \text{ The division ring is a field (so multiplication commutes)}
\end{equation*}

\subsection{Pascal's theorem}
\begin{theorem}
    Informally: Choose any six points on an ellipse, seperate your ellipse into two, so that three points lie on one side and three points lie on the other side. Number the points on the first side as 1,2,3 and likewise for the points on the other side. 
    then join them to every point of a different number on the opposite side, looking at the intersection point of these lines.
    These three intersection points lie on a straight line.
\end{theorem}

    \href{https://youtu.be/-9qugwEZDJs?t=955}{\includegraphics[scale = 0.25]{pascal_theorem_pic}}

    \

    \textit{Illustration from the lecture video}

    \

The line on which their intersection lies is called the \textbf{Pascal line}.

\

Pappus' theorem is a degenerate case of Pascal's theorem, Pascal's theorm holds for any degree two curve and two straight lines are a degenerate case of a degree 2 curve.

How do we prove Pascal's theorem? We will use a proof using Algebraic Geometry and Bézout's theorem. 

\begin{proof}
    We number the lines as in the picture above (noting that they form a funny kind of hexagon) and choose six linear polynomials, 
    $p_i$, for $i\in \{1,\dots, 6\}$ where $p_i = 0$ on line $i$.

    Now look at $p_1p_3p_5$ and $p_2p_4p_6$, these polynomials vanish on all six points, so choose $\lambda$ such that:\begin{equation}
        p_1p_3p_5 - \lambda p_2p_4p_6 \text{ this is of degree 3 curve}
    \end{equation}
    Vanishes on a seventh point of the conic. Since the conic is of degree $2$, by Bézout there are at most $6$ intersection points 
    UNLESS they have a common component. So the conic must be contained in the degree $3$ curve.

    So this degree $3$ curve is equal to the union of a conic and a line, which is Pascal's line. Indeed since $p_1p_3p_5$ and $p_2p_4p_6$ both vanish on the 
    three intersection points, since they are on the curve but not on the conic, they must be on the line.
\end{proof}

\section{Kakeya sets}

We will continue to look at examples from Algebraic Geometry. Kakeya Sets are constructs from real analysis.

\begin{definition}
    The first definition of a \textbf{Kakeya set} is a set such that if you have a unit line in the set we can turn the line around
    in the set, for e.g. A circle, or an equilateral triange.

    Slight variation of the defintion, is that it is a set contianing a unit line in every direction.
\end{definition}

    A Kakeya set over a finite field F is a set that contains a line in every direction. A conjecture from T.Wolff:

    \begin{center}
    The size  of a Kakeya set over $F$ in $F^n$ is at least $c_n|F|^n$.
\end{center}
    
    This was proved in 2008 by Dvir with $c_n = \frac{1}{n!}$.
    
    The proof is in two steps:\begin{enumerate}
        \item  A Kakeya Set in $F^n$ cannot lie in a hypersurface of degree $d<|F|$.
        \begin{proof}
            Suppose $f$ is a polynomial of degree $d<|F|$ defining a hypersurface which is a Kakeya Set, and let $f_d$ be the highest degree component.
            Note that for any $v$ we can find $x$ so that $f(x+vt)$ vanishes for all $t$. This is what is meant by the zeroes of $f$ are a Kakeya set.
            For any direction $v$ we can find a line such that $f$ vanishes on that line.

            \

            So coefficient $f_d(v)$ of $t^d$ vanishes for any $v$, so $f_d$ has degree < $|F|$, since if $f_d$ was non-zero it would have at most $< |F|$ zeroes
            we must have that $f_d = 0$. So $f = 0$.
        \end{proof} 

        \item Observe, the polynomials of degree at most $|F|-1$ form a vector space of dimension $\binom{n+|F|-1}{n}$.

        So we can find hypersurface of degree at most $|F|-1$ vanishing on any set with less than $\binom{n+|F|-1}{n}$ points.
    \end{enumerate}

So a Kakeya set has at least $\binom{n+|F|-1}{n}$ points, but \begin{equation*}
    \binom{n+|F|-1}{n} = \frac{|F|(|F|+1)\cdots (|F|+n-1)}{1\cdot 2 \cdots n} \geq \frac{|F|^n}{n!}
\end{equation*}
    
\begin{example}
    27 lines on a cubic surface.

We will prove that the cubic surface:\begin{equation*}
    w^3+x^3+y^3+z^3 = 0 \text{ in }\mathbb{P}^3
\end{equation*}
Has exactly 27 lines on it.

\

Note $(w\colon x\colon y\colon z)\in \mathbb{P}^3$ then $(w\colon x\colon y\colon z) = (\lambda w\colon \lambda x\colon \lambda y\colon \lambda z)$, for all $\lambda\neq 0$.


Note there is an obvious line:\begin{equation*}
    (a\colon -a \colon b \colon -b) \text{ since }a^3+(-a)^3+b^3+(-b)^3 = 0
\end{equation*}

Note we can permute the coordinates and we can multiply by $\omega$ such that $\omega^3 = 1$.

This gives us $3\times 3 \times 3 = 27$ possibilities.

\end{example} 

\lecture{}
\section{Affine space and Zariski topology}

\subsection{Affine space}

\begin{definition}
    Let $k$ be any field (most commononly taken as $\C$, $\R$ or a finite field), then an \textbf{Affine space} is just $k^n$ as a vector space, with slightly different automorphism group.
    \begin{itemize}
        \item automorphism of a vector space is:\begin{equation*}
            GL_n(k) = \{n\times n\text{ matrices such that }\det \neq 0\}
        \end{equation*} 
        \item automorphism of Affine space is:\begin{equation*}
            GL_n(k) \text{ and } \{\text{translations, i.e a map }x\rightarrow x+v\text{ for some vector }v\}
        \end{equation*}

        If $n=2$ the group can be pictured of as the group of matrices of the following shape:
        \[\begin{bmatrix}
            \ast_1 & \ast_1 & \ast_2\\
            \ast_1 & \ast_1 & \ast_2\\
            0 & 0 & 1
        \end{bmatrix}\]

        Where $\begin{bmatrix}
            \ast_1 & \ast_1 \\
            \ast_1 & \ast_1 
        \end{bmatrix}\in GL_n(k)$ and $\begin{bmatrix}
             \ast_2\\
             \ast_2
        \end{bmatrix}$ corresponds to a translation.
    \end{itemize}
    We write an affine space as $\mathbb{A}^n$.

    Roughly speaking an affine space is a vector space where we have ``forgotten'' what our origin is.

    If we have a vector space we can get an affine space by ``forgotting'' $0$, and if we have an affine space we can choose any point to be the origin and it gives us a vector space.
\end{definition}

\begin{example}
    Note that if we look at the universe, the $3D$ space we live in is an affine space as there is no natural way to choose the origin.
    But if we choose the origin to be the center of the earth then $3D$ space becomes a vector space.
\end{example}

\subsubsection{Affine geometry}
\begin{definition}
    \textbf{Affine geometry} can be thought as the study of affine space that is invariant under translations and linear transformations.
\end{definition}

\paragraph*{Properties of affine geometry}

\begin{itemize}
    \item points
    \item lines
    \item parallel lines
    \item conics
    \item Polynomial functions
\end{itemize}

Are all well-defined in affine geometry.

\paragraph*{Not affine geometry}
\begin{itemize}
    \item circles
    \item angles
    \item lengths
\end{itemize}

\paragraph*{Coordinate ring of $\mathbb{A}^n$}
Algebraic geometry tends to use the coordinate ring of affine space.\begin{definition}
    The coordinate ring of $\mathbb{A}^n$, is just the space of polynomials on $\mathbb{A}^n$. Where $k$ is infinite.
    If we got affine space we can reconstruct the ring of polynomials on it. Conversely if we are given a polynomial ring over $k$ we can reconstruct affine space as:\begin{align*}
        \mathbb{A}^n &= \{\text{homomorphism from }k[x_1,\dots,x_n] \rightarrow k \text{ (as a k-algebra)} \}\\ 
    \end{align*}
    
    Indeed a homomorphism taking $k[x_1,\dots,x_n]\rightarrow k$, just takes $x_i\rightarrow a_i$ for some $a_i\in k$. This corresponds to the point $(a_1,\dots,a_n)\in \mathbb{A}^n$.    
\end{definition}

Because of this the study of affine space is more or less equivalent to the study of this polynomial ring. In particular the automorphism group of these two are the same.

\subsection{Zariski topology}
\begin{definition}
    An \textbf{algebraic set} is a set of zeros of some set of polynomials in $k[x_1,\dots,x_n]$. 
\end{definition}

\begin{example}
    If $f(x,y) = x^2+y^2-1$, then our algebric set is the circle. 
\end{example}
\begin{example}
    If $f(x) = x-a$ and $g(y) = y-b$, the our algebraic set is the point $(a,b)$.
\end{example}

Algebraic sets are closed under these operations:\begin{itemize}
    \item Intersection: Indeed if $C_1,C_2,\dots$ are the zero sets of $P_1,P_2,\dots$ then $\bigcap C_i$ are the zeroes of $\bigcup P_i$.
    \item Finite unions: If $C_1,C_2$ are the zeroes of $\{f_1,f_2,\dots\}$ and $\{g_1,\dots\}$ respectively, then $C_1\cup C_2$ are the zeroes of $\{{f_i}{g_j}\}$
    \item Clear that $\mathbb{A}^n$ and $\emptyset$ are algebraic sets, taking the zero set of $0$ and of a constant non-zero polynomial respectively.
\end{itemize}

With these properties we see that we can create a topology where the closed sets are the algebraic sets. We call this topology the \textbf{Zariski topology}. 

\begin{example}
    Take ${\mathbb{A}^1}$, this is just the line. The closed sets:\begin{itemize}
        \item $\mathbb{A}^1$, the zero set of $0$.
        \item Any finite sets, since $\{a_1,\dots,a_n\}$ is the zero set of $(x-a_1)\cdots (x-a_n)$
    \end{itemize}

These are the only closed sets, since a polynomial in one variable is either the zero polynomial or has a finite amount of roots.


Take any points $x\neq y$ and nbhs $U$ of $x$ and $V$ of $y$. Since $U^c$ and $V^c$ are finite (note if they are infinite then $U$ or $V$ is the empty set which is impossible). So $U$ and $V$ both contain all the points of $\mathbb{A}^1$
except for a finite number of points. Since $k$ is infinite this means that $U\cap V \neq \emptyset$. This is true for all nbhs of $x$ and $y$, which means this space is not Haussdorff.
\end{example}

\begin{example}
    Take $\mathbb{A}^2$. The closed sets are:\begin{itemize}
        \item Points $(a,b)$
        \item Any curve, the set of zero of $f(x,y) = 0$
        \item Union of finite amount of curves and points
    \end{itemize}

    Note $\mathbb{A}^2\neq \mathbb{A}^1\times \mathbb{A}^1$. Indeed since $\mathbb{A}^1\times \mathbb{A}^1$ are unions of finite amount of vertical lines, horizontal lines and points.
\end{example}

\begin{example}
    \textbf{\textit{Determinantal variety:}}
Take $\mathbb{A}^{mn} = \text{linear maps }k^m\rightarrow k^n = m\times n \text{ matrices}$

Determinantal variety = set all linear maps of rank $\leq i$.

\

We claim that this is an algebraic set. Indeed this set is given by the vanishing of all $(i+1)\times (i+1)$ minors of $m\times n$ matrix. This is a set of polynomials.

In partucular the subset of maps from $k^m\rightarrow k^n$ that are onto is open in the Zariski topology.
\end{example}

\section{Noetherian spaces and Noetherian Rings}

\subsection{Noetherian rings}
\begin{definition}
    A \textbf{Noetherian ring} is a ring satisfying these three equivalent conditions:\begin{itemize}
        \item Every ideal is finitely generated
        \item Every nonempty set of ideals has a maximal element
        \item Every chain of increasing ideals,$I_0\subseteq I_1\subseteq I_2\subseteq \dots$, is eventaully constant. I.e. there is a $n$ such that $I_n=I_m$ for all $m\geq n$. 
    \end{itemize}
\end{definition}
\begin{theorem} \textbf{\textit{Noether}}

    \

    If $R$ is Noetherian then $R[x]$ is Noetherian.
    \begin{proof}
        Let $I$ be an ideal of $R[x]$ and look at the chain $I_0\subseteq I_1\subseteq I_2\subseteq \dots$, of $R$ where:\begin{equation*}
            I_n = \text{leading coeffs of polynomials of degree }\leq n\text{ in I}
        \end{equation*}
Since $R$ is Noetherian this stabilises, so $I_N=I_{N+1}=\dots$, for some $N$.

Take the set of polynomials $s_0,s_1,\dots,s_N$ where:\begin{equation*}
    s_i= \text{ degree }i\text{ polynomials whose leading coefficients generate }I_i, \text{ for }i=1,\dots,N
\end{equation*}
Note the sets $s_i$ are finite since $R$ is Noetherian.


Then $s_0,s_1,\dots,s_N$ generate the ideal $I$.
    \end{proof}
\end{theorem}
\begin{corollary} \textbf{\textit{Hilbert}}

    \

    $k[x_1,\dots,x_n]$ is Noetherian

    \begin{proof}
        Since $k$ is a field any ideal in $k$ is either generated by $0$ or generated by $1$. So $k$ is Noetherian, so $k[x_1]$ is Noetherian.
        So inductively we can see that $k[x_1,\dots,x_n]$ is Noetherian.
    \end{proof}
\end{corollary}

\subsection{Noetherian spaces}

\begin{definition}
    A topological space is called \textbf{Noetherian} if equivalently:\begin{itemize}
        \item The closed sets satisfy the descsending chain condition. So any decreasing sequence:\begin{equation*}
            C_0\supseteq C_1\supseteq C_2\supseteq \dots
        \end{equation*}
        Stabilises, i.e. $C_n=C_{n+1}=\dots$, for some $n$
        \item Any nonempty collection of closed sets has a minimal element.
    \end{itemize}
\end{definition}
These are in some sense the dual of the definition of Noetherian Ring.

\begin{theorem}
    $\mathbb{A}^n$ with Zariski topology is Noetherian.

    \begin{proof}
        Sketch:

        Closed sets of $\mathbb{A}^n$ correspond to some ideals of $k[x_1,\dots,x_n]$. A descsending chains of closed sets of $\mathbb{A}^n$ correspond to an ascending chain of ideals in $k[x_1,\dots,x_n]$
    \end{proof}
\end{theorem}

\

Noetherian spaces are ``WEIRD'', the Noetherian condition is equivalent to saying that every open set is compact or quasicompact. Note quasicompact actually means the same as the regualar defintion of compact, Bourbaki made a mistake in the defintion and 
only considered Haussdorff compact spaces to be compact, so when non-Haussdorff compact spaces were seen to be important they had to use the term quasicompact.

\

\paragraph*{Borcherds' Rule of Thumb} If we see the word ``quasi'' in mathematics then someone, somewhere and somewhen screwed up the terminology and had to use the term ``quasi'' to fix it.

\

\begin{remark}
    In analysis we almost never see open compact sets, it can be shown that if a space is Noetherian and Haussdorff then it is finite.
\end{remark}

\subsection{A first definition of Algebraic Varieties}

\subsubsection{Irreducible sets}

\begin{definition}
    A set is called \textbf{irreducible} if and only if it is nonempty and not the union of $2$ proper closed subsets.
\end{definition}

\begin{definition}
    \textbf{Noetherian Induction}, pick a maximal closed set of some collection of closed sets.
\end{definition}

\begin{theorem}
    Any Noetherian space is a finite union of irreducible subspaces.

    \begin{proof}
        Proof by Noetherian Induction:

        We will show that every closed subset is a finite union of irreducibles. If not, pick a minimal counterexample $C$. We have two cases\begin{enumerate}
            \item If $C$ is irreducible, then we are done and we have found a contradiction
            \item If $C$ is not irreducible, then we can write $C=C_1\cup C_2$, where $C_1,C_2$ are smaller. By induction, $C_1,C_2$ are a finite union of irreducible sets, and so is $C$. Which is a contradiction.
        \end{enumerate}

        In all cases we have a contradiction so, there can't be a closed set that is not a finite union of irreducibles. So all closed sets, in particular the whole space is a finite union of irreducibles.
    \end{proof}
\end{theorem}

So we can reduce the study of Noetherian spaces to the study of irreducible Noetherian spaces.


\

\begin{corollary}
    Every algebraic set is a finite union of irreducible algebraic sets.
\end{corollary}

\begin{definition}
    \textbf{A provisional definition of Algebraic Varieties}:
    
    They are irreducible closed subset of affine space.
\end{definition}

\subsubsection{Examples}

\begin{example}
  This definition is not perfect. Suppose we take the variety given by: $xy=1$ and the set of nonzero points in $\mathbb{A}^1$.

Note the set of nonzero points in $\mathbb{A}^1$ is not a closed set, but since we can map the hyperbola to this by the mapping $(x,y)\rightarrow x$, we should consider it an algebraic variety.

\

\href{https://youtu.be/D_eJ8BWLb24?t=1110}{\includegraphics[scale = 0.25]{algebraic-varieties.png}}

\

We shall give a better definition later (I guess we can clook at these like ``quasi-algebraic varieties'').
\end{example}

\begin{example}
    Take the algebraic set defined by $x^2+y^2 - 2z^2 = 0 \text{ and }2x^2-y^2-z^2 = 0$.

    This is the union of four irreducible subsets:\begin{enumerate}
        \item $x=y=z$
        \item $x=0y=z$
        \item $x=-y=-z$
        \item $x=y=-z$
    \end{enumerate}

    So the intersection of irreducible sets may not be irreducible.
\end{example}
\newpage 
\begin{example}
    If we take $xy=0$, we have the union of the $x$-axis and the $y$-axis.

    \

    If we take $xy=1$, the we hyperbola, which is irreducible and connected in the Zariski topology, but disconnected in the usual topology.

    \

\href{https://youtu.be/D_eJ8BWLb24?t=1295}{\includegraphics[scale=0.25]{connected-irreducible-spaces}}

\end{example}

We have now conclueded the section on Noetherian spaces, next section we will look at the Hilbert Nullstellensatz, and the connection between Algebraic Varieties and Ideals.

\end{document}
